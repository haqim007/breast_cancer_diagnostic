{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Intro","metadata":{}},{"cell_type":"markdown","source":"This notebook was created for learning purpose","metadata":{}},{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Dataset","metadata":{}},{"cell_type":"markdown","source":"Dataset source: https://www.kaggle.com/uciml/breast-cancer-wisconsin-data","metadata":{}},{"cell_type":"code","source":"dataset = pd.read_csv('../input/breast-cancer-wisconsin-data/data.csv')\ndataset.head()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"dataset.describe()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset['diagnosis'].describe()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_corr = dataset.drop([\"id\", \"Unnamed: 32\"], axis=1).corr(\"spearman\")\n\nplt.figure(figsize=(20,8))\nsns.heatmap(get_corr, annot=True, cmap='BrBG')\nplt.show()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"markdown","source":"## Check for null values","metadata":{}},{"cell_type":"code","source":"cols_null = pd.DataFrame(dataset.isnull().sum())\ncols_null = cols_null.reset_index().rename(columns={'index': 'Title', 0: 'Total'})\ncols_null.loc[:, 'Percentage'] = cols_null.apply(lambda row: row['Total']/dataset.shape[0] * 100, axis=1)\ncols_null","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del cols_null","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Check for duplicated values","metadata":{}},{"cell_type":"code","source":"dataset[dataset.duplicated()]","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Label encoding","metadata":{}},{"cell_type":"code","source":"# use it later\n# from sklearn.preprocessing import OrdinalEncoder\n\n# # define ordinal encoding\n# encoder = OrdinalEncoder()\n# # transform data\n# result = encoder.fit_transform(dataset[['diagnosis']])\n# encoder.inverse_transform(result)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Check for imbalanced dataset ","metadata":{}},{"cell_type":"code","source":"dataset[['diagnosis']].value_counts()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset[['diagnosis']].value_counts()/len(dataset[['diagnosis']].index) * 100","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## TTS","metadata":{}},{"cell_type":"code","source":"X = dataset.drop([\"id\", \"diagnosis\", \"Unnamed: 32\"],1)\ny = dataset['diagnosis']","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state = 123)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Standardization","metadata":{}},{"cell_type":"code","source":"import time\nfrom sklearn.preprocessing import StandardScaler\nstart_time = time.time()\n\nfor x in X:\n    dataset[x] = StandardScaler().fit_transform(dataset[x].values.reshape(len(dataset), 1))\n\nprint(\"--- %s seconds ---\" % (time.time() - start_time))\ndataset.head()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Handle Imbalanced data","metadata":{}},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\noversample = SMOTE(random_state=1)\nundersample = RandomUnderSampler(sampling_strategy='majority', random_state=1)\n\n# print(\"origin\")\n# print(X_train.shape, y_train.shape)\n# print(y_train.value_counts())\n# print(\"oversample\")\nX_train_o, y_train_o = oversample.fit_resample(X_train, y_train)\n# print(X_train_o.shape, y_train_o.shape)\n# print(y_train_o.value_counts())\n# print(\"undersample\")\nX_train_u, y_train_u = undersample.fit_resample(X_train, y_train)\n# print(X_train_u.shape, y_train_o.shape)\n# print(y_train_u.value_counts())\n\ndata_train = {\"origin\":{\"X_train\":X_train, \"y_train\": y_train}, \n                   \"oversample\":{\"X_train\":X_train_o, \"y_train\": y_train_o},\n                  \"undersample\":{\"X_train\":X_train_u, \"y_train\": y_train_u}}","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"code","source":"from imblearn.pipeline import Pipeline","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Function to evaluate model","metadata":{}},{"cell_type":"code","source":"# ## function to evaluate model\nfrom sklearn.metrics import accuracy_score\ndef eval_model(model,X_test,y_test, X_train, y_train):\n    y_pred = model.predict(X_test)\n    y_train_pred = model.predict(X_train)\n    return pd.DataFrame({\"test score\":[accuracy_score(y_test,y_pred)], \"train score\":[accuracy_score(y_train,y_train_pred)]})\n\nfrom sklearn.model_selection import cross_val_score\ndef get_cross_val(model, X_train, y_train):\n    accuracy = cross_val_score(model, X_train, y_train, scoring='accuracy', cv = 10)\n#     print(accuracy)\n    #get the mean of each fold \n    return accuracy.mean()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SVM","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data_train\nfor dt in data_train:\n    score = get_cross_val(SVC(),data_train[dt]['X_train'], data_train[dt]['y_train'])\n    print(dt, score)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipeline_svc = Pipeline(steps=[(\"stdScaller\", StandardScaler()), ('model', SVC())])\nhighest_score = 0\nhighest_score_dt = \"\"\nfor dt in data_train:\n#     print(dt)\n    score = get_cross_val(pipeline_svc,data_train[dt]['X_train'], data_train[dt]['y_train'])\n    if (score > highest_score):\n        highest_score = score\n        highest_score_dt = dt\n#     print(score)\n# print()\nprint(\"highest score:\",highest_score_dt, highest_score)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pipeline_svc.fit(X_train_o, y_train_o)\npipeline_svc.fit(data_train[highest_score_dt]['X_train'], data_train[highest_score_dt]['y_train'])\neval_model(pipeline_svc,X_test,y_test, data_train[highest_score_dt]['X_train'], data_train[highest_score_dt]['y_train'])","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_train = pipeline_svc.predict(X_test)\ny_pred_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = pipeline_svc.predict(X_test)\ny_pred","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Logistic Regression","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\npipeline_LogRes = Pipeline(steps=[(\"stdScaller\", StandardScaler()), ('model', LogisticRegression())])\nhighest_score = 0\nhighest_score_dt = \"\"\nfor dt in data_train:\n#     print(dt)\n    score = get_cross_val(pipeline_LogRes,data_train[dt]['X_train'], data_train[dt]['y_train'])\n    if (score > highest_score):\n        highest_score = score\n        highest_score_dt = dt\n#     print(score)\n# print()\nprint(\"highest score:\",highest_score_dt, highest_score)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pipeline_LogRes = Pipeline(steps=[('smote', SMOTE(random_state=1)),(\"stdScaller\", StandardScaler()), ('model', LogisticRegression())], verbose=True)\n# pipeline_LogRes.fit(X_train, y_train)\n# eval_model(pipeline_LogRes,X_test,y_test, X_train, y_train)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## KNN","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\npipeline_KNN = Pipeline(steps=[(\"stdScaller\", StandardScaler()), ('model', KNeighborsClassifier())])\nhighest_score = 0\nhighest_score_dt = \"\"\nfor dt in data_train:\n#     print(dt)\n    score = get_cross_val(pipeline_KNN,data_train[dt]['X_train'], data_train[dt]['y_train'])\n    if (score > highest_score):\n        highest_score = score\n        highest_score_dt = dt\n#     print(score)\n# print()\nprint(\"highest score:\",highest_score_dt, highest_score)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.neighbors import KNeighborsClassifier\n# # ('over', RandomOverSampler(random_state=1)),('under', RandomUnderSampler(random_state=1)),('smote', SMOTE(random_state=1)),\n# pipeline_KNN = Pipeline(steps=[('over', RandomOverSampler(random_state=1)), (\"stdScaller\", StandardScaler()), ('model', KNeighborsClassifier())])\n# pipeline_KNN.fit(X_train, y_train)\n# eval_model(pipeline_KNN,X_test,y_test, X_train, y_train)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Decision Tree","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\npipeline_tree = Pipeline(steps=[(\"stdScaller\", StandardScaler()), ('model', DecisionTreeClassifier())])\nhighest_score = 0\nhighest_score_dt = \"\"\nfor dt in data_train:\n#     print(dt)\n    score = get_cross_val(pipeline_tree,data_train[dt]['X_train'], data_train[dt]['y_train'])\n    if (score > highest_score):\n        highest_score = score\n        highest_score_dt = dt\n#     print(score)\n# print()\nprint(\"highest score:\",highest_score_dt, highest_score)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.tree import DecisionTreeClassifier\n\n# pipeline_tree = Pipeline(steps=[(\"stdScaller\", StandardScaler()),('smote', SMOTE()),('over', RandomOverSampler()),('under', RandomUnderSampler()), ('model', DecisionTreeClassifier())])\n# pipeline_tree.fit(X_train, y_train)\n# eval_model(pipeline_tree,X_test,y_test, X_train, y_train)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Ensemble Method - Voting Classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier\nlist_model = [(\"svc\", pipeline_svc), (\"lr\", pipeline_LogRes), (\"knn\", pipeline_KNN), ('dtree', pipeline_tree)]\npipeline_svc = Pipeline(steps=[(\"stdScaller\", StandardScaler()), ('model', VotingClassifier(list_model))])\nhighest_score = 0\nhighest_score_dt = \"\"\nfor dt in data_train:\n#     print(dt)\n    score = get_cross_val(pipeline_svc,data_train[dt]['X_train'], data_train[dt]['y_train'])\n    if (score > highest_score):\n        highest_score = score\n        highest_score_dt = dt\n#     print(score)\n# print()\nprint(\"highest score:\",highest_score_dt, highest_score)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.ensemble import VotingClassifier\n\n# list_model = [(\"svc\", pipeline_svc), (\"lr\", pipeline_LogRes), (\"knn\", pipeline_KNN), ('dtree', pipeline_tree)]\n# voting = VotingClassifier(list_model)\n# voting.fit(X_train, y_train)\n# eval_model(voting,X_test,y_test, X_train, y_train)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Ensemble Method - Bagging","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import BaggingClassifier\npipeline_bagging = Pipeline(steps=[(\"stdScaller\", StandardScaler()), ('model', BaggingClassifier())])\nhighest_score = 0\nhighest_score_dt = \"\"\nfor dt in data_train:\n#     print(dt)\n    score = get_cross_val(pipeline_bagging,data_train[dt]['X_train'], data_train[dt]['y_train'])\n    if (score > highest_score):\n        highest_score = score\n        highest_score_dt = dt\n#     print(score)\n# print()\nprint(\"highest score:\",highest_score_dt, highest_score)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.ensemble import BaggingClassifier\n\n# pipeline_bagging = Pipeline(steps=[(\"StdScaler\", StandardScaler()), (\"smote\", SMOTE()), (\"under\", RandomUnderSampler()), (\"over\", RandomOverSampler()), (\"model\", BaggingClassifier())])\n# pipeline_bagging.fit(X_train, y_train)\n# eval_model(pipeline_bagging,X_test,y_test, X_train, y_train)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Ensemble Method - Random Forest","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\npipeline_rf = Pipeline(steps=[(\"stdScaller\", StandardScaler()), ('model', RandomForestClassifier())])\nhighest_score = 0\nhighest_score_dt = \"\"\nfor dt in data_train:\n#     print(dt)\n    score = get_cross_val(pipeline_rf,data_train[dt]['X_train'], data_train[dt]['y_train'])\n    if (score > highest_score):\n        highest_score = score\n        highest_score_dt = dt\n#     print(score)\n# print()\nprint(\"highest score:\",highest_score_dt, highest_score)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.ensemble import RandomForestClassifier\n\n# pipeline_rf = Pipeline(steps=[(\"StdScaler\", StandardScaler()), (\"smote\", SMOTE()), (\"under\", RandomUnderSampler()), (\"over\", RandomOverSampler()), (\"model\", RandomForestClassifier())])\n# pipeline_rf.fit(X_train, y_train)\n# eval_model(pipeline_rf,X_test,y_test, X_train, y_train)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Tunning Hyperparameter","metadata":{}},{"cell_type":"markdown","source":"I chose Logistic Regression because it has the highest score on training and testing","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nparam_grid = {'model__penalty' : ['l1', 'l2'],\n    'model__C' : np.logspace(-4, 4, 20),\n    'model__solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n             'model__max_iter':[4000]}\ngrid = GridSearchCV(estimator=pipeline_LogRes, param_grid=param_grid, scoring = 'accuracy',n_jobs = 2,cv=3)\ngrid.fit(X_train, y_train)\n\ngrid.best_params_\n","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Final Model","metadata":{}},{"cell_type":"markdown","source":"need to recreate model using pipeline sklearn","metadata":{}},{"cell_type":"code","source":"voting = VotingClassifier(list_model, voting=\"hard\")\nvoting.fit(X_train, y_train)\neval_model(voting,X_test,y_test, X_train, y_train)\n","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"voting.predict(X_test)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]}]}
